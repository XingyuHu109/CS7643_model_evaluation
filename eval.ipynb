{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nykSszsK-Dp"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2xdwCn4LGdX"
      },
      "source": [
        "# Make sure to apply for access to the llama3 models on huggingface(all llama family models require it). After that create a personal access token on [hugging face](https://huggingface.co/settings/tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kD1v7iRLYoG"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gWGjdNC-oMS"
      },
      "outputs": [],
      "source": [
        "# check if gpu works\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZQaGS_RAMjeF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import snapshot_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GeAJ0bRIEvQw"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"my_results\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlwCB9U6GEhX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWgyp8SIHS_8"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/XingyuHu109/LLM-Pruner.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDbTX67UKKko"
      },
      "outputs": [],
      "source": [
        "!pip install -r LLM-Pruner/requirement.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Y6BUfSJGJb"
      },
      "outputs": [],
      "source": [
        "snapshot_download(repo_id=\"Neooooo/cs7643_models\", local_dir=\"./LLM-Pruner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BIYXTvKyIdQO"
      },
      "outputs": [],
      "source": [
        "# Choosing tasks to review\n",
        "tasks = [\"openbookqa\", \"arc_easy\", \"winogrande\", \"hellaswag\", \"arc_challenge\", \"piqa\", \"boolq\"]\n",
        "tasks = \",\".join(tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "JRLjbHnBLrR9"
      },
      "outputs": [],
      "source": [
        "path_to_pruned_weights = \"prune_log/vanilla_llama_1b_prune_0.25/pytorch_model.bin\"\n",
        "path_to_tuned_weights = \"tune_log/llama3_1b_0.25_tune\"\n",
        "original_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "report_name = \"llama3_1b_0.25_benchmark.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "x1eYHhvEUWEn"
      },
      "outputs": [],
      "source": [
        "os.environ['PATH_TO_PRUNED_WEIGHTS'] = path_to_pruned_weights\n",
        "os.environ['PATH_TO_TUNED_WEIGHTS'] = path_to_tuned_weights\n",
        "os.environ['ORIGINAL_MODEL'] = original_model\n",
        "os.environ['TASKS'] = tasks\n",
        "os.environ['REPORT_NAME'] = report_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scQ33IRpNvtH"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "export PYTHONPATH='./LLM-Pruner'\n",
        "export HF_DATASETS_TRUST_REMOTE_CODE=true\n",
        "python LLM-Pruner/lm-evaluation-harness/main.py --model hf-causal-experimental \\\n",
        "       --model_args \"checkpoint=$PATH_TO_PRUNED_WEIGHTS,peft=$PATH_TO_TUNED_WEIGHTS,config_pretrained=$ORIGINAL_MODEL\" \\\n",
        "       --tasks \"$TASKS\" \\\n",
        "       --device cuda:0 --no_cache \\\n",
        "       --output_path \"../my_results/$REPORT_NAME\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HXA-H5MVQaTy"
      },
      "outputs": [],
      "source": [
        "# Additionally test speed-up and resource usage"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
